{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.models import AlexNet, AlexNet_Weights\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.io import read_image\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lognormal Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lognormal(x, a, mu, sigma):\n",
    "    \"\"\"\n",
    "    Formula for the lognormal distribution.\n",
    "    \"\"\"\n",
    "    scale = a / (x * sigma * np.sqrt(2 * np.pi))\n",
    "    term = np.exp(-0.5 * np.square((np.log(x) - mu) / sigma))\n",
    "    return scale * term\n",
    "\n",
    "def get_weight_hist(weights, min_val=None, max_val=None):\n",
    "    \"\"\"\n",
    "    Gets a histogram of the weights for a given model.\n",
    "    Returns the middle of each bin + their count + the min and max value in the histogram.\n",
    "    \"\"\"\n",
    "    params = weights.flatten()\n",
    "    params = torch.abs(params)\n",
    "    if min_val == None or max_val == None:\n",
    "        min_val = params.min().item()\n",
    "        max_val = params.max().item()\n",
    "    bins = 50\n",
    "    hist = torch.histc(params, bins=bins, min=min_val, max=max_val)\n",
    "    bin_mids = np.array([min_val + i * (max_val - min_val) / bins + 0.5 * (max_val - min_val) / bins for i in range(bins)])\n",
    "    hist = hist.detach().cpu().numpy()\n",
    "    return bin_mids, hist, min_val, max_val\n",
    "\n",
    "def get_lognormal_params(weights):\n",
    "    \"\"\"\n",
    "    Gets lognormal parameters for a given set of weights.\n",
    "    \"\"\"\n",
    "    bin_mids, hist, min_val, max_val = get_weight_hist(weights)\n",
    "    popt, pcov = curve_fit(lognormal, bin_mids, hist, p0=(1, 0, 2))\n",
    "    return popt, min_val, max_val\n",
    "\n",
    "def compute_layer_rsq(weights, a, mu, sigma, min_val, max_val):\n",
    "    \"\"\"\n",
    "    Computes r squared between a layer's weights and given parameters for a lognormal curve.\n",
    "    \"\"\"\n",
    "    bin_mids, hist, _, _ = get_weight_hist(weights, min_val, max_val)\n",
    "    y_fit = lognormal(bin_mids, a, mu, sigma)\n",
    "    rsq = r2_score(y_fit, hist)\n",
    "    return rsq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogNormalOptimizer(torch.optim.Optimizer):\n",
    "    \"\"\"\n",
    "    Performs SGD with a custom lognormal step.\n",
    "    \"\"\"\n",
    "    def __init__(self, params, lr, momentum, weight_decay, dampening=0, popts=False, min_val=False, max_val=False, a=10, b=4.61):\n",
    "        \"\"\"\n",
    "        Standard initialization\n",
    "        \"\"\"\n",
    "        defaults = dict(lr=lr, \n",
    "                        momentum=momentum, \n",
    "                        weight_decay=weight_decay, \n",
    "                        dampening=dampening, \n",
    "                        popts=popts, \n",
    "                        min_val=min_val, \n",
    "                        max_val=max_val,\n",
    "                        a=a,\n",
    "                        b=b)\n",
    "        super(LogNormalOptimizer, self).__init__(params, defaults)\n",
    "\n",
    "\n",
    "    def _init_group(self, group, params_with_grad, d_p_list, momentum_buffer_list):\n",
    "        for p in group['params']:\n",
    "            if p.grad is not None:\n",
    "                params_with_grad.append(p)\n",
    "                d_p_list.append(p.grad)\n",
    "                if p.grad.is_sparse:\n",
    "                    raise RuntimeError(\"What is a sparse gradient?\")\n",
    "\n",
    "                state = self.state[p]\n",
    "                if 'momentum_buffer' not in state:\n",
    "                    momentum_buffer_list.append(None)\n",
    "                else:\n",
    "                    momentum_buffer_list.append(state['momentum_buffer'])\n",
    "        \n",
    "\n",
    "    def sgd(self, params_with_grad, d_p_list, momentum_buffer_list, lr, momentum, weight_decay, dampening, popts, min_val, max_val, a, b):\n",
    "        for i, param in enumerate(params_with_grad):\n",
    "\n",
    "            d_p = d_p_list[i]\n",
    "\n",
    "            # Weight decay\n",
    "            if weight_decay != 0:\n",
    "                d_p = d_p.add(param, alpha=weight_decay)\n",
    "\n",
    "            # Momentum\n",
    "            if momentum != 0:\n",
    "                buf = momentum_buffer_list[i]\n",
    "\n",
    "                if buf is None:\n",
    "                    buf = torch.clone(d_p).detach()\n",
    "                    momentum_buffer_list[i] = buf\n",
    "                else:\n",
    "                    buf.mul_(momentum).add_(d_p, alpha=1 - dampening)\n",
    "\n",
    "                d_p = buf\n",
    "\n",
    "            \"\"\"\n",
    "            This is where the lognormal optimization happen!\n",
    "            R squared is computed between current weights and 'optimal' lognormal params.\n",
    "            We use exponential decay to reduce learning rate the closer Rsq gets to 1 with:\n",
    "            decay = a * e^(-b*Rsq)\n",
    "            \"\"\"\n",
    "            if max_val:\n",
    "                rsq = compute_layer_rsq(param, *popts, min_val, max_val)\n",
    "                exp_decay = a * np.exp(-b * rsq)\n",
    "                d_p = d_p.mul(exp_decay)\n",
    "\n",
    "            param.data.add_(d_p, alpha=-lr)\n",
    "            \n",
    "\n",
    "    def step(self, closure=None):\n",
    "        for group in self.param_groups:\n",
    "            # Prepare group for backprop\n",
    "            params_with_grad = []\n",
    "            d_p_list = []\n",
    "            momentum_buffer_list = []\n",
    "            self._init_group(group, params_with_grad, d_p_list, momentum_buffer_list)\n",
    "\n",
    "            self.sgd(params_with_grad, \n",
    "                     d_p_list, \n",
    "                     momentum_buffer_list, \n",
    "                     group[\"lr\"], \n",
    "                     group[\"momentum\"], \n",
    "                     group[\"weight_decay\"], \n",
    "                     group[\"dampening\"], \n",
    "                     group[\"popts\"], \n",
    "                     group[\"min_val\"], \n",
    "                     group[\"max_val\"],\n",
    "                     group[\"a\"],\n",
    "                     group[\"b\"])\n",
    "\n",
    "            # update momentum_buffers in state\n",
    "            for p, momentum_buffer in zip(params_with_grad, momentum_buffer_list):\n",
    "                state = self.state[p]\n",
    "                state['momentum_buffer'] = momentum_buffer\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomAlexNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Custom AlexNet model that replaces the final linear classification layer with\n",
    "    one with the correct number of outputs.\n",
    "    Creates a module list for each layer so that we can store our lognormal parameters.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        self.model = AlexNet()\n",
    "        self.model.classifier[6] = torch.nn.Linear(4096, n_classes)\n",
    "\n",
    "        self.params = torch.nn.ModuleDict({\n",
    "            'layer0': torch.nn.ModuleList([self.model.features[0]]),\n",
    "            'layer1': torch.nn.ModuleList([self.model.features[3]]),\n",
    "            'layer2': torch.nn.ModuleList([self.model.features[6]]),\n",
    "            'layer3': torch.nn.ModuleList([self.model.features[8]]),\n",
    "            'layer4': torch.nn.ModuleList([self.model.features[10]]),\n",
    "            'layer5': torch.nn.ModuleList([self.model.classifier[1]]),\n",
    "            'layer6': torch.nn.ModuleList([self.model.classifier[4]]),\n",
    "            'layer7': torch.nn.ModuleList([self.model.classifier[6]]),\n",
    "        })\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.model.forward(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve popts from trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lognormal_from_saved_model(path):\n",
    "    base_model = CustomAlexNet(10)\n",
    "    base_model.load_state_dict(torch.load(path))\n",
    "\n",
    "    popts = []\n",
    "    mins = []\n",
    "    maxes = []\n",
    "    for l in range(len(base_model.params)):\n",
    "        popt, min_val, max_val = get_lognormal_params(base_model.params[f\"layer{l}\"][0].weight)\n",
    "        popts.append(popt)\n",
    "        mins.append(min_val)\n",
    "        maxes.append(max_val)\n",
    "\n",
    "    lognormal_params = {\"popts\": popts, \"mins\": mins, \"maxes\": maxes}\n",
    "\n",
    "    rsqs = []\n",
    "    for l in range(len(base_model.params)):\n",
    "        rsqs.append(compute_layer_rsq(base_model.params[f\"layer{l}\"][0].weight, *(popts[l]), mins[l], maxes[l]))\n",
    "\n",
    "    return lognormal_params, rsqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_ds, valid_ds, test_ds, lognormal_params=None, epochs=10, batch_size=128, lr=1e-2, momentum=0.9, weight_decay=0.0005):\n",
    "\n",
    "    # Load data\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    valid_dl = DataLoader(valid_ds, batch_size=batch_size, shuffle=True)\n",
    "    test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Tensorboard\n",
    "    run = len(os.listdir(os.path.join(os.getcwd(), \"runs\")))\n",
    "    run_path = os.path.join(os.getcwd(), f\"runs/{run}\")\n",
    "    writer = SummaryWriter(run_path)\n",
    "    print(f\"Logging to {run}\")\n",
    "\n",
    "    # Train setup\n",
    "    model = CustomAlexNet(n_classes=10)\n",
    "    model.to(device)\n",
    "\n",
    "    if lognormal_params:\n",
    "        print(\"Optimizing with lognormal params\")\n",
    "        # Set up parameters by layer\n",
    "        params = [{'params': model.params[f\"layer{l}\"].parameters(),\n",
    "                   'popts': lognormal_params['popts'][l],\n",
    "                   'min_val': lognormal_params['mins'][l],\n",
    "                   'max_val': lognormal_params['maxes'][l],\n",
    "                   'a': lognormal_params['a'],\n",
    "                   'b': lognormal_params['b']} for l in range(len(model.params))]\n",
    "        optimizer = LogNormalOptimizer(params, lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "    else:\n",
    "        print(\"Optimizing with SGD\")\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    step = 0\n",
    "    train_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for img, label in tqdm(train_dl):\n",
    "            # Train step\n",
    "            img, label = img.to(device), label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(img)\n",
    "            loss = loss_fn(logits, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Loss tracking\n",
    "            writer.add_scalar(\"train_loss\", loss.item(), step)\n",
    "            train_losses.append(loss.item())\n",
    "            step += 1\n",
    "\n",
    "        # Evaluate epoch\n",
    "        val_total = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for img, label in tqdm(valid_dl):\n",
    "                img, label = img.to(device), label.to(device)\n",
    "                logits = model(img)\n",
    "                # Loss tracking\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                correct = torch.sum((preds.squeeze() == label.squeeze()).long()).item()\n",
    "                val_total += correct\n",
    "        print(f\"epoch {epoch} accuracy: {val_total / (len(valid_ds))}\")\n",
    "\n",
    "\n",
    "    # Evaluate epoch\n",
    "    test_total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for img, label in tqdm(test_dl):\n",
    "            img, label = img.to(device), label.to(device)\n",
    "            logits = model(img)\n",
    "            # Loss tracking\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            correct = torch.sum((preds.squeeze() == label.squeeze()).long()).item()\n",
    "            test_total += correct\n",
    "    test_acc = test_total / len(test_ds)\n",
    "    print(f\"test accuracy: {test_acc}\")\n",
    "\n",
    "    return model, train_losses, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "preprocess = AlexNet_Weights.IMAGENET1K_V1.transforms()\n",
    "ds = CIFAR10(root=os.path.join(os.getcwd(), \"data/cifar10\"), train=True, transform=preprocess)\n",
    "train_ds, valid_ds = torch.utils.data.random_split(ds, lengths=[0.8, 0.2], generator=torch.Generator().manual_seed(42))\n",
    "test_ds = CIFAR10(root=os.path.join(os.getcwd(), \"data/cifar10\"), train=False, transform=preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trial(lognormal_params, alexnet_hyperparams, a, b, epochs, trial_name):\n",
    "    if a:\n",
    "        print(f\"Running lognormal trial {trial_name}\")\n",
    "        l_params = lognormal_params\n",
    "        l_params[\"a\"] = a\n",
    "        l_params[\"b\"] = b\n",
    "    else:\n",
    "        print(f\"Running base trial {trial_name}\")\n",
    "        l_params = None\n",
    "    model, losses, acc = train_model(train_ds, valid_ds, test_ds, lognormal_params=l_params, epochs=epochs, **alexnet_hyperparams)\n",
    "\n",
    "    # Save losses\n",
    "    path = f\"saved/{trial_name}_epoch{epochs-1}\"\n",
    "    with open(f\"{path}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(losses, f)\n",
    "    # Save model\n",
    "    torch.save(model.state_dict(), f\"{path}.pt\")\n",
    "    # Save acc\n",
    "    with open(f\"{path}.txt\", \"w\") as f:\n",
    "        f.write(str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running lognormal trial lognormal\n",
      "Logging to 123\n",
      "Optimizing with lognormal params\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [30:20<00:00,  5.82s/it]\n",
      "100%|██████████| 79/79 [00:22<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 accuracy: 0.0973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:21<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.1\n"
     ]
    }
   ],
   "source": [
    "# Train model and get train loss\n",
    "# Note: This will not work until you have run a base trial. Then you need to point to that saved trial.\n",
    "lognormal_params, _ = get_lognormal_from_saved_model(\"saved/template/base_model_epoch9.pt\")\n",
    "alexnet_hyperparams = {\"lr\": 1e-2, \"momentum\": 0.9, \"weight_decay\": 0.0005, \"batch_size\": 128}\n",
    "trials = [\n",
    "    # {\"trial_name\": \"base\",\n",
    "    #  \"alpha\": None,\n",
    "    #  \"epochs\": 1},\n",
    "     {\"trial_name\": \"lognormal\",\n",
    "      \"a\": 10,\n",
    "      \"b\": 4.61,\n",
    "      \"epochs\": 1}\n",
    "]\n",
    "for trial in trials:\n",
    "    run_trial(lognormal_params, alexnet_hyperparams, **trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.301945447921753, 9.451831817626953, 62.217315673828125, 60.539161682128906, 108.92694091796875, 294.7548522949219, 289.81427001953125, 482.5779724121094, 814.6224365234375, 771.3228759765625, 813.501708984375, 1132.205078125, 4413.083984375, 4823.359375, 93472.5, 851771456.0, 3.488316729092853e+28, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_results(base_name, trial_list):\n",
    "    with open(f\"saved/{base_name}.pkl\", \"rb\") as f:\n",
    "        losses = pickle.load(f)\n",
    "        plt.plot(range(len(losses)), losses, label=\"SGD\")\n",
    "\n",
    "    for trial in trial_list:\n",
    "        with open(f\"saved/{trial}.pkl\", \"rb\") as f:\n",
    "            lognormal_losses = pickle.load(f)\n",
    "            print(lognormal_losses)\n",
    "            plt.plot(range(len(lognormal_losses)), lognormal_losses, label=f\"lognormal\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Batch\")\n",
    "    plt.show()\n",
    "\n",
    "base_name = \"base_epoch0\"\n",
    "plot_list = [\"lognormal_epoch0\"]\n",
    "plot_results(base_name, plot_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hopfield",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
