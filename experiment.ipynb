{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.models import AlexNet, AlexNet_Weights\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.io import read_image\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\"\n",
    "BINS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lognormal Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lognormal(X, a, mu, sigma):\n",
    "    scale = X.multiply(sigma * (2 * torch.pi)**0.5).reciprocal().multiply(a)\n",
    "    exponent = torch.exp(-0.5 * (torch.log(X).subtract(mu)).divide(sigma).pow(2))\n",
    "    return scale.multiply(exponent)\n",
    "\n",
    "\n",
    "def compute_rsq(y_pred, y_true):\n",
    "    ssr = torch.sum(torch.pow((y_true - y_pred), 2))\n",
    "    sst = torch.sum(torch.pow((y_true - torch.mean(y_true)), 2))\n",
    "    rsq = 1 - ssr / sst\n",
    "    return rsq\n",
    "\n",
    "\n",
    "def get_weight_hist(weights, a, mu, sigma):\n",
    "    weights = weights.flatten()\n",
    "    weights = torch.abs(weights)\n",
    "    min_val = weights.min().item()\n",
    "    max_val = weights.max().item()\n",
    "    y_pred = torch.histc(weights, bins=BINS, min=min_val, max=max_val).to(device)\n",
    "    X = torch.tensor([min_val + i * (max_val - min_val) / BINS + 0.5 * (max_val - min_val) / BINS for i in range(BINS)]).to(device)\n",
    "    y_true = lognormal(X, a, mu, sigma)\n",
    "    return y_pred, y_true\n",
    "\n",
    "\n",
    "def compute_layer_rsq(weights, a, mu, sigma):\n",
    "    y_pred, y_true = get_weight_hist(weights, a, mu, sigma)\n",
    "    rsq = compute_rsq(y_pred, y_true).item()\n",
    "    return max(rsq, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lognormal_old(x, a, mu, sigma):\n",
    "    \"\"\"\n",
    "    Formula for the lognormal distribution.\n",
    "    \"\"\"\n",
    "    scale = a / (x * sigma * np.sqrt(2 * np.pi))\n",
    "    term = np.exp(-0.5 * np.square((np.log(x) - mu) / sigma))\n",
    "    return scale * term\n",
    "\n",
    "def get_weight_hist_old(weights, min_val=None, max_val=None):\n",
    "    \"\"\"\n",
    "    Gets a histogram of the weights for a given model.\n",
    "    Returns the middle of each bin + their count + the min and max value in the histogram.\n",
    "    \"\"\"\n",
    "    params = weights.flatten()\n",
    "    params = torch.abs(params)\n",
    "    if min_val == None or max_val == None:\n",
    "        min_val = params.min().item()\n",
    "        max_val = params.max().item()\n",
    "    # TODO: Try sampling the number of points\n",
    "    # TODO: Try reducing the number of bins\n",
    "    hist = torch.histc(params, bins=BINS, min=min_val, max=max_val)\n",
    "    bin_mids = np.array([min_val + i * (max_val - min_val) / BINS + 0.5 * (max_val - min_val) / BINS for i in range(BINS)])\n",
    "    hist = hist.detach().cpu().numpy()\n",
    "    return bin_mids, hist\n",
    "\n",
    "def get_lognormal_params(weights):\n",
    "    \"\"\"\n",
    "    Gets lognormal parameters for a given set of weights.\n",
    "    \"\"\"\n",
    "    bin_mids, hist = get_weight_hist_old(weights)\n",
    "    popt, pcov = curve_fit(lognormal_old, bin_mids, hist, p0=(1, 0, 2))\n",
    "    return popt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogNormalOptimizer(torch.optim.Optimizer):\n",
    "    \"\"\"\n",
    "    Performs SGD with a custom lognormal step.\n",
    "    \"\"\"\n",
    "    def __init__(self, params, lr, momentum, weight_decay, dampening=0, popts=False, alpha=None, beta=None):\n",
    "        \"\"\"\n",
    "        Standard initialization\n",
    "        \"\"\"\n",
    "        defaults = dict(lr=lr, \n",
    "                        momentum=momentum, \n",
    "                        weight_decay=weight_decay, \n",
    "                        dampening=dampening, \n",
    "                        popts=popts, \n",
    "                        alpha=alpha,\n",
    "                        beta=beta)\n",
    "        super(LogNormalOptimizer, self).__init__(params, defaults)\n",
    "\n",
    "\n",
    "    def _init_group(self, group, params_with_grad, d_p_list, momentum_buffer_list):\n",
    "        for p in group['params']:\n",
    "            if p.grad is not None:\n",
    "                params_with_grad.append(p)\n",
    "                d_p_list.append(p.grad)\n",
    "                if p.grad.is_sparse:\n",
    "                    raise RuntimeError(\"What is a sparse gradient?\")\n",
    "\n",
    "                state = self.state[p]\n",
    "                if 'momentum_buffer' not in state:\n",
    "                    momentum_buffer_list.append(None)\n",
    "                else:\n",
    "                    momentum_buffer_list.append(state['momentum_buffer'])\n",
    "        \n",
    "\n",
    "    def sgd(self, params_with_grad, d_p_list, momentum_buffer_list, lr, momentum, weight_decay, dampening, popts, alpha, beta):\n",
    "        for i, param in enumerate(params_with_grad):\n",
    "\n",
    "            d_p = d_p_list[i]\n",
    "\n",
    "            # Weight decay\n",
    "            if weight_decay != 0:\n",
    "                d_p = d_p.add(param, alpha=weight_decay)\n",
    "\n",
    "            # Momentum\n",
    "            if momentum != 0:\n",
    "                buf = momentum_buffer_list[i]\n",
    "\n",
    "                if buf is None:\n",
    "                    buf = torch.clone(d_p).detach()\n",
    "                    momentum_buffer_list[i] = buf\n",
    "                else:\n",
    "                    buf.mul_(momentum).add_(d_p, alpha=1 - dampening)\n",
    "\n",
    "                d_p = buf\n",
    "\n",
    "            \"\"\"\n",
    "            This is where the lognormal optimization happen!\n",
    "            R squared is computed between current weights and 'optimal' lognormal params.\n",
    "            We use exponential decay to reduce learning rate the closer Rsq gets to 1 with:\n",
    "            decay = a * e^(-b*Rsq)\n",
    "            \"\"\"\n",
    "            if alpha:\n",
    "                rsq = compute_layer_rsq(param, *popts)\n",
    "                exp_decay = alpha * math.exp(-beta * rsq)\n",
    "                d_p = d_p.mul(exp_decay)\n",
    "\n",
    "            param.data.add_(d_p, alpha=-lr)\n",
    "            \n",
    "\n",
    "    def step(self, closure=None):\n",
    "        for group in self.param_groups:\n",
    "            # Prepare group for backprop\n",
    "            params_with_grad = []\n",
    "            d_p_list = []\n",
    "            momentum_buffer_list = []\n",
    "            self._init_group(group, params_with_grad, d_p_list, momentum_buffer_list)\n",
    "\n",
    "            self.sgd(params_with_grad, \n",
    "                     d_p_list, \n",
    "                     momentum_buffer_list, \n",
    "                     group[\"lr\"], \n",
    "                     group[\"momentum\"], \n",
    "                     group[\"weight_decay\"], \n",
    "                     group[\"dampening\"], \n",
    "                     group[\"popts\"], \n",
    "                     group[\"alpha\"],\n",
    "                     group[\"beta\"])\n",
    "\n",
    "            # update momentum_buffers in state\n",
    "            for p, momentum_buffer in zip(params_with_grad, momentum_buffer_list):\n",
    "                state = self.state[p]\n",
    "                state['momentum_buffer'] = momentum_buffer\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomAlexNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Custom AlexNet model that replaces the final linear classification layer with\n",
    "    one with the correct number of outputs.\n",
    "    Creates a module list for each layer so that we can store our lognormal parameters.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        self.model = AlexNet()\n",
    "        self.model.classifier[6] = torch.nn.Linear(4096, n_classes)\n",
    "        self.params = torch.nn.ModuleDict({\n",
    "            'layer0': torch.nn.ModuleList([self.model.features[0]]),\n",
    "            'layer1': torch.nn.ModuleList([self.model.features[3]]),\n",
    "            'layer2': torch.nn.ModuleList([self.model.features[6]]),\n",
    "            'layer3': torch.nn.ModuleList([self.model.features[8]]),\n",
    "            'layer4': torch.nn.ModuleList([self.model.features[10]]),\n",
    "            'layer5': torch.nn.ModuleList([self.model.classifier[1]]),\n",
    "            'layer6': torch.nn.ModuleList([self.model.classifier[4]]),\n",
    "            'layer7': torch.nn.ModuleList([self.model.classifier[6]]),\n",
    "        })\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.model.forward(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve popts from trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lognormal_from_saved_model(path):\n",
    "    base_model = CustomAlexNet(10)\n",
    "    base_model.load_state_dict(torch.load(path))\n",
    "\n",
    "    lognormal_params = []\n",
    "    for l in range(len(base_model.params)):\n",
    "        popts = get_lognormal_params(base_model.params[f\"layer{l}\"][0].weight)\n",
    "        lognormal_params.append({\"popts\": popts})\n",
    "\n",
    "    \n",
    "    rsqs = []\n",
    "    for l in range(len(base_model.params)):\n",
    "        rsqs.append(compute_layer_rsq(base_model.params[f\"layer{l}\"][0].weight, *lognormal_params[l][\"popts\"]))\n",
    "\n",
    "    return lognormal_params, rsqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9789476990699768, 0.9999962449073792, 0.9690545797348022, 0.9963454008102417, 0.9888451099395752, 0.956462025642395, 0.6249033212661743, 0.9991908669471741]\n"
     ]
    }
   ],
   "source": [
    "lp, rsqs = get_lognormal_from_saved_model(\"saved/template/base_model_epoch9.pt\")\n",
    "print(rsqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_ds, valid_ds, test_ds, lognormal_params=None, epochs=10, batch_size=128, lr=1e-2, momentum=0.9, weight_decay=0.0005):\n",
    "\n",
    "    # Load data\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    valid_dl = DataLoader(valid_ds, batch_size=batch_size, shuffle=True)\n",
    "    test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Tensorboard\n",
    "    run = len(os.listdir(os.path.join(os.getcwd(), \"runs\")))\n",
    "    run_path = os.path.join(os.getcwd(), f\"runs/{run}\")\n",
    "    writer = SummaryWriter(run_path)\n",
    "    print(f\"Logging to {run}\")\n",
    "\n",
    "    # Train setup\n",
    "    model = CustomAlexNet(n_classes=10)\n",
    "    model.to(device)\n",
    "\n",
    "    if lognormal_params:\n",
    "        print(\"Optimizing with lognormal params\")\n",
    "        # Set up parameters by layer\n",
    "        to_lognormal = [0, 0, 0, 0, 0, 1, 1, 1]\n",
    "        optim_params = [{'params': model.params[f\"layer{l}\"].parameters(),\n",
    "                        'popts': lognormal_params[l]['popts'] if to_lognormal[l] else None,\n",
    "                        'alpha': lognormal_params[l]['alpha'] if to_lognormal[l] else None,\n",
    "                        'beta': lognormal_params[l]['beta'] if to_lognormal[l] else None} for l in range(len(model.params))]\n",
    "        print(optim_params)\n",
    "        optimizer = LogNormalOptimizer(optim_params, lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "    else:\n",
    "        print(\"Optimizing with SGD\")\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    step = 0\n",
    "    train_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for img, label in tqdm(train_dl):\n",
    "            # Train step\n",
    "            img, label = img.to(device), label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(img)\n",
    "            loss = loss_fn(logits, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Loss tracking\n",
    "            writer.add_scalar(\"train_loss\", loss.item(), step)\n",
    "            train_losses.append(loss.item())\n",
    "            step += 1\n",
    "\n",
    "        # Evaluate epoch\n",
    "        val_total = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for img, label in tqdm(valid_dl):\n",
    "                img, label = img.to(device), label.to(device)\n",
    "                logits = model(img)\n",
    "                # Loss tracking\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                correct = torch.sum((preds.squeeze() == label.squeeze()).long()).item()\n",
    "                val_total += correct\n",
    "        print(f\"epoch {epoch} accuracy: {val_total / (len(valid_ds))}\")\n",
    "\n",
    "\n",
    "    # Evaluate epoch\n",
    "    test_total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for img, label in tqdm(test_dl):\n",
    "            img, label = img.to(device), label.to(device)\n",
    "            logits = model(img)\n",
    "            # Loss tracking\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            correct = torch.sum((preds.squeeze() == label.squeeze()).long()).item()\n",
    "            test_total += correct\n",
    "    test_acc = test_total / len(test_ds)\n",
    "    print(f\"test accuracy: {test_acc}\")\n",
    "\n",
    "    return model, train_losses, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "preprocess = AlexNet_Weights.IMAGENET1K_V1.transforms()\n",
    "ds = CIFAR10(root=os.path.join(os.getcwd(), \"data/cifar10\"), train=True, transform=preprocess)\n",
    "train_ds, valid_ds = torch.utils.data.random_split(ds, lengths=[0.8, 0.2], generator=torch.Generator().manual_seed(42))\n",
    "test_ds = CIFAR10(root=os.path.join(os.getcwd(), \"data/cifar10\"), train=False, transform=preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trial(lognormal_params, alexnet_hyperparams, alpha, beta, epochs, trial_name):\n",
    "    if lognormal_params:\n",
    "        print(f\"Running lognormal trial {trial_name}\")\n",
    "        for params in lognormal_params:\n",
    "            params[\"alpha\"] = alpha\n",
    "            params[\"beta\"] = beta\n",
    "    else:\n",
    "        print(f\"Running base trial {trial_name}\")\n",
    "    model, losses, acc = train_model(train_ds, valid_ds, test_ds, lognormal_params=lognormal_params, epochs=epochs, **alexnet_hyperparams)\n",
    "\n",
    "    # Save losses\n",
    "    path = f\"saved/{trial_name}_epoch{epochs-1}\"\n",
    "    with open(f\"{path}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(losses, f)\n",
    "    # Save model\n",
    "    torch.save(model.state_dict(), f\"{path}.pt\")\n",
    "    # Save acc\n",
    "    with open(f\"{path}.txt\", \"w\") as f:\n",
    "        f.write(str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def calc_beta_from_alpha(alpha):\n",
    "    return np.log(alpha**2)\n",
    "\n",
    "def plot_exp_decay(alpha, beta):\n",
    "    ys = []\n",
    "    xs = list(range(0, 1000, 1))\n",
    "    for x in xs:\n",
    "        ys.append(alpha * np.exp(-beta * x/1000))\n",
    "    plt.ylim(0, max(ys))\n",
    "    plt.grid()\n",
    "    plt.plot([x / 1000 for x in xs], ys)\n",
    "    plt.show()\n",
    "\n",
    "plot_exp_decay(10, 2.87)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running lognormal trial base?\n",
      "Logging to 12\n",
      "Optimizing with lognormal params\n",
      "[{'params': <generator object Module.parameters at 0x318686c00>, 'popts': None, 'alpha': None, 'beta': None}, {'params': <generator object Module.parameters at 0x318686ce0>, 'popts': None, 'alpha': None, 'beta': None}, {'params': <generator object Module.parameters at 0x318686dc0>, 'popts': None, 'alpha': None, 'beta': None}, {'params': <generator object Module.parameters at 0x318686ea0>, 'popts': None, 'alpha': None, 'beta': None}, {'params': <generator object Module.parameters at 0x318686f80>, 'popts': None, 'alpha': None, 'beta': None}, {'params': <generator object Module.parameters at 0x318687060>, 'popts': array([ 1.24971955e+05, -5.34095080e+00,  7.11712459e-01]), 'alpha': None, 'beta': None}, {'params': <generator object Module.parameters at 0x318687140>, 'popts': array([ 5.20577335e+04, -4.85026151e+00,  9.70780613e-01]), 'alpha': None, 'beta': None}, {'params': <generator object Module.parameters at 0x318687220>, 'popts': array([485.54615616,  -4.20069671,   0.78479006]), 'alpha': None, 'beta': None}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [03:27<00:00,  1.51it/s]\n",
      "100%|██████████| 79/79 [00:22<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 accuracy: 0.3391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [03:27<00:00,  1.51it/s]\n",
      "100%|██████████| 79/79 [00:22<00:00,  3.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 accuracy: 0.4724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [03:32<00:00,  1.47it/s]\n",
      "100%|██████████| 79/79 [00:22<00:00,  3.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 accuracy: 0.5324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [03:29<00:00,  1.49it/s]\n",
      "100%|██████████| 79/79 [00:22<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 accuracy: 0.6378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [03:29<00:00,  1.50it/s]\n",
      "100%|██████████| 79/79 [00:22<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 accuracy: 0.6956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [03:28<00:00,  1.50it/s]\n",
      "100%|██████████| 79/79 [00:21<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 accuracy: 0.7405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [03:28<00:00,  1.50it/s]\n",
      "100%|██████████| 79/79 [00:21<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 accuracy: 0.7217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [03:30<00:00,  1.49it/s]\n",
      "100%|██████████| 79/79 [00:22<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 accuracy: 0.7616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [03:29<00:00,  1.50it/s]\n",
      "100%|██████████| 79/79 [00:22<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 accuracy: 0.7769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [03:27<00:00,  1.51it/s]\n",
      "100%|██████████| 79/79 [00:23<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 accuracy: 0.792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:22<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.7869\n"
     ]
    }
   ],
   "source": [
    "# Train model and get train loss\n",
    "# Note: This will not work until you have run a base trial. Then you need to point to that saved trial.\n",
    "lognormal_params, _ = get_lognormal_from_saved_model(\"saved/template/base_model_epoch9.pt\")\n",
    "alexnet_hyperparams = {\"lr\": 1e-2, \"momentum\": 0.9, \"weight_decay\": 0.0005, \"batch_size\": 128}\n",
    "#A = [1.5, 2, 3, 5, 10]\n",
    "alpha = 10\n",
    "beta = 3\n",
    "trials = [\n",
    "      # {\"trial_name\": f\"lognormal_alpha{alpha}_beta{beta}\",\n",
    "      # \"alpha\": alpha,\n",
    "      # \"beta\": beta,\n",
    "      # \"epochs\": 10},\n",
    "    {\"trial_name\": f\"base?\",\n",
    "     \"alpha\": None,\n",
    "     \"beta\": None,\n",
    "      \"epochs\": 10},\n",
    "]\n",
    "for trial in trials:\n",
    "    run_trial(lognormal_params, alexnet_hyperparams, **trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'saved/base.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/danyoung/workspace/columbia/cris/jaynes-alexnet/experiment.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danyoung/workspace/columbia/cris/jaynes-alexnet/experiment.ipynb#X21sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danyoung/workspace/columbia/cris/jaynes-alexnet/experiment.ipynb#X21sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m base_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbase\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/danyoung/workspace/columbia/cris/jaynes-alexnet/experiment.ipynb#X21sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m plot_results(base_name, [\u001b[39m\"\u001b[39;49m\u001b[39mbase_epoch9\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mlognormal_alpha10_beta3_epoch9\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n",
      "\u001b[1;32m/Users/danyoung/workspace/columbia/cris/jaynes-alexnet/experiment.ipynb Cell 18\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/danyoung/workspace/columbia/cris/jaynes-alexnet/experiment.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot_results\u001b[39m(base_name, trial_list):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/danyoung/workspace/columbia/cris/jaynes-alexnet/experiment.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msaved/\u001b[39;49m\u001b[39m{\u001b[39;49;00mbase_name\u001b[39m}\u001b[39;49;00m\u001b[39m.pkl\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/danyoung/workspace/columbia/cris/jaynes-alexnet/experiment.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         losses \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(f)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/danyoung/workspace/columbia/cris/jaynes-alexnet/experiment.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         plt\u001b[39m.\u001b[39mplot(\u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(losses)), losses, label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSGD\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/workspace/columbia/cris/jaynes-alexnet/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    280\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    281\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m     )\n\u001b[0;32m--> 286\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'saved/base.pkl'"
     ]
    }
   ],
   "source": [
    "def plot_results(base_name, trial_list):\n",
    "    with open(f\"saved/{base_name}.pkl\", \"rb\") as f:\n",
    "        losses = pickle.load(f)\n",
    "        plt.plot(range(len(losses)), losses, label=\"SGD\")\n",
    "\n",
    "    for trial in trial_list:\n",
    "        with open(f\"saved/{trial}.pkl\", \"rb\") as f:\n",
    "            lognormal_losses = pickle.load(f)\n",
    "            plt.plot(range(len(lognormal_losses)), lognormal_losses, label=f\"lognormal\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Batch\")\n",
    "    plt.show()\n",
    "\n",
    "plot_results(\"base_epoch9\", [\"lognormal_alpha10_beta3_epoch9\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hopfield",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
